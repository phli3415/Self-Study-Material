{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例1：大模型分析工具的调用",
   "id": "3c7c33dc622a6c04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1、获取大模型\n",
    "# 导入相关依赖\n",
    "from langchain_community.tools import MoveFileTool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# 定义LLM模型\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2、获取工具的列表\n",
    "tools = [MoveFileTool()]\n",
    "\n",
    "# 3、因为大模型invoke调用时，需要传入函数的列表，所以需要将工具转换为函数\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "\n",
    "# 4、获取消息列表\n",
    "messages = [HumanMessage(content=\"将文件a移动到桌面\")]\n",
    "\n",
    "# 5、调用大模型（传入消息列表、工具的列表）\n",
    "response = chat_model.invoke(\n",
    "    input=messages,\n",
    "    # tools = tools, #不支持\n",
    "    functions = functions,\n",
    ")\n",
    "print(response)"
   ],
   "id": "684c8207c0e9d66d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "作为对比:",
   "id": "99693396f31abbf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 获取消息列表\n",
    "messages = [HumanMessage(content=\"查询一下明天北京的天气\")]\n",
    "\n",
    "# 调用大模型（传入消息列表、工具的列表）\n",
    "response = chat_model.invoke(\n",
    "    input=messages,\n",
    "    # tools = tools, #不支持\n",
    "    functions = functions,\n",
    ")\n",
    "\n",
    "print(response)"
   ],
   "id": "f7f94ee7067b7303",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "通过上面两个测试发现，得到的AIMessage的核心属性如下：\n",
    "\n",
    "1、如果分析出需要调用对应的工具：\n",
    "\n",
    "content: 信息为空。因为大模型要调用工具，所以就不会直接返回信息给用户\n",
    "\n",
    "additional_kwargs: 包含 function_call 字段，指明具体函数调用的参数和函数名。比如：\n",
    "\n",
    "additional_kwargs={'function_call': {'arguments': '{\"source_path\":\"a\",\"destination_path\":\"/Users/YourUsername/Desktop/a\"}', 'name': 'move_file'}, 'refusal': None}\n",
    "\n",
    "2. 如果分析出不需要调用对应的工具：\n",
    "\n",
    "content: 信息不为空。\n",
    "\n",
    "additional_kwargs: 不包含\n",
    "\n",
    "# 举例2：如何调用具体大模型分析出来的工具\n",
    "\n",
    "说明：\n",
    "\n",
    "1、大模型与Agent的核心区别：是否涉及到工具的调用\n",
    "\n",
    "2、针对于大模型：仅能分析出要调用的工具，但是此工具（或函数）不能真正的执行\n",
    "\n",
    "针对于Agent: 除了分析出要调用的工具之外，还可以执行具体的工具（或函数"
   ],
   "id": "c1763608666ad391"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1、获取大模型\n",
    "# 导入相关依赖\n",
    "from langchain_community.tools import MoveFileTool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# 定义LLM模型\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 2、获取工具的列表\n",
    "tools = [MoveFileTool()]\n",
    "\n",
    "# 3、因为大模型invoke调用时，需要传入函数的列表，所以需要将工具转换为函数\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "\n",
    "# 4、获取消息列表\n",
    "messages = [HumanMessage(content=\"将文件a移动到桌面\")]\n",
    "\n",
    "# 5、调用大模型（传入消息列表、工具的列表）\n",
    "response = chat_model.invoke(\n",
    "    input=messages,\n",
    "    # tools = tools, #不支持\n",
    "    functions = functions,\n",
    ")\n",
    "print(response)"
   ],
   "id": "33f1b2e8b0eb4708",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 分析下要调用哪个工具或函数",
   "id": "fd9540c84da32f4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if \"function_call\" in response.additional_kwargs:\n",
    "    tool_name = response.additional_kwargs[\"function_call\"][\"name\"]\n",
    "    tool_args = response.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "    print(f\"调用工具: {tool_name} \\n参数: {tool_args}\")\n",
    "\n",
    "else :\n",
    "\n",
    "    print(f\"模型回复: {response.content}\")"
   ],
   "id": "5495aa2041c83845",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
