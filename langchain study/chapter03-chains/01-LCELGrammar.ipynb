{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 关于LCEL语法的使用\n",
    "\n",
    "在使**用 $|$** 之前的举例:"
   ],
   "id": "67c97dbb5eaf82ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 引入依赖包\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.utils import pre_init\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# 初始化语言模型\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "joke_query = \"告诉我一个笑话。\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 以PromptTemplate为例\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"\"\"回答用户的查询。\\n满足的格式为{format_instructions}\\n问题为{question}\\n\"\"\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# prompt = prompt_template.invoke(input={\"question\": joke_query})\n",
    "# response = chat_model.invoke(prompt)\n",
    "# print(response)\n",
    "\n",
    "# json_result = parser.invoke(response)\n",
    "\n",
    "chain = prompt_template|chat_model|parser\n",
    "response = chain.invoke(input={\"question\" : joke_query})\n",
    "print(response)"
   ],
   "id": "5bbeeb648dcecfe4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 2、顺序链之SimpleSequentialChain的使用\n",
    "\n",
    "举例1:"
   ],
   "id": "3f8894eb1e9298a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chainA_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位精通各领域知识的知名教授\"),\n",
    "        (\"human\", \"请你尽可能详细的解释一下: {knowledge}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 假设 llm 已经是一个有效的语言模型实例\n",
    "# 例如：from langchain_openai import ChatOpenAI; llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 请确保在运行代码时 llm 变量已定义。\n",
    "\n",
    "chainA_chains = LLMChain(llm=llm,\n",
    "                         prompt=chainA_template,\n",
    "                         verbose=True\n",
    ")\n",
    "\n",
    "# # chainA_chains.invoke({\"knowledge\": \"什么是LangChain？\"})"
   ],
   "id": "74fe31034fd76d29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain # Assuming LLMChain is imported from the previous snippet\n",
    "\n",
    "chainB_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你非常善于提取文本中的重要信息, 并做出简短的总结\"),\n",
    "        (\"human\", \"这是针对一个提问的完整的解释说明内容: {description}\"),\n",
    "        (\"human\", \"请你根据上述说明, 尽可能简短的输出重要的结论, 请控制在20个字以内\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 假设 chat_model 已经是一个有效的语言模型实例\n",
    "# 例如：from langchain_openai import ChatOpenAI; chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 请确保在运行代码时 chat_model 变量已定义。\n",
    "\n",
    "chainB_chains = LLMChain(llm=chat_model,\n",
    "                         prompt=chainB_template,\n",
    "                         verbose=True\n",
    ")"
   ],
   "id": "a18ccb22f1753281",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain.chains.sequential import SimpleSequentialChain # 假设 SimpleSequentialChain 已导入\n",
    "\n",
    "full_chain = SimpleSequentialChain(\n",
    "    chains = [chainA_chains, chainB_chains],\n",
    "    verbose=True\n",
    ")\n",
    "# 说明: 针对于SimpleSequentialChain而言, 唯一的输入变量名是: input\n",
    "# 就算前面叫Knowledge也只能写input\n",
    "response = full_chain.invoke(input={\"input\" :\"什么是LangChain\"})\n",
    "\n",
    "print(response)"
   ],
   "id": "e4dfea702ffc68e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "# 2.创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 3.定义一个给剧名写大纲的LLMChain\n",
    "template1 = \"\"\"你是个剧作家。给定剧本的标题，你的工作就是为这个标题写一个大纲。\n",
    "Title: {title}\n",
    "\"\"\"\n",
    "prompt_template1 = PromptTemplate(input_variables=[\"title\"], template=template1)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template1)\n",
    "# 4.定义给一个剧本大纲写一篇评论的LLMChain\n",
    "template2 = \"\"\"你是《纽约时报》的剧评家。有了剧本的大纲，你的工作就是为剧本写一篇评论\n",
    "剧情大纲:\n",
    "{synopsis}\n",
    "\"\"\"\n",
    "prompt_template2 = PromptTemplate(input_variables=[\"synopsis\"], template=template2)\n",
    "review_chain = LLMChain(llm=llm, prompt=prompt_template2)\n",
    "# 5.定义一个完整的链按顺序运行这两条链\n",
    "#(verbose=True:打印链的执行过程)\n",
    "overall_chain = SimpleSequentialChain(\n",
    "chains=[synopsis_chain, review_chain], verbose=True\n",
    ") #\n",
    "# 6.调用完整链顺序执行这两个链\n",
    "review = overall_chain.invoke(\"日落海滩上的悲剧\")\n",
    "# 7.打印结果\n",
    "print(review)"
   ],
   "id": "5a1204dc729c7594",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3、顺序链之SequentialChain的使用\n",
    "举例1:"
   ],
   "id": "e7a98615625b19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from openai import OpenAI\n",
    "import os\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "schainA_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一位精通各领域知识的知名教授\"),\n",
    "        (\"human\", \"请你先尽可能详细的解释一下：{knowledge}，并且{action}\")\n",
    "    ]\n",
    ")\n",
    "schainA_chains = LLMChain(llm=llm,\n",
    "    prompt=schainA_template,\n",
    "    verbose=True,\n",
    "    output_key=\"schainA_chains_key\"\n",
    ")\n",
    "\n",
    "\n",
    "schainB_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你非常善于提取文本中的重要信息，并做出简短的总结\"),\n",
    "        (\"human\", \"这是针对一个提问完整的解释说明内容：{schainA_chains_key}\"),\n",
    "        (\"human\", \"请你根据上述说明，尽可能简短的输出重要的结论，请控制在100个字以内\"),\n",
    "    ]\n",
    ")\n",
    "schainB_chains = LLMChain(llm=llm,\n",
    "    prompt=schainB_template,\n",
    "    verbose=True,\n",
    "    output_key='schainB_chains_key'\n",
    ")\n",
    "\n",
    "# 一定要声明两个变量: input_variables, output_variables\n",
    "Seq_chain = SequentialChain(\n",
    "    chains=[schainA_chains, schainB_chains],\n",
    "    input_variables=[\"knowledge\", \"action\"],\n",
    "    output_variables=[\"schainA_chains_key\",\"schainB_chains_key\"],\n",
    "    verbose=True)\n",
    "\n",
    "response = Seq_chain.invoke({\n",
    "    \"knowledge\":\"中国足球为什么踢得烂\",\n",
    "    \"action\":\"举一个实际的例子\"\n",
    "    })\n",
    "print(response)"
   ],
   "id": "513c065b3e539ab1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 可以单独打印\n",
    "print(response[\"schainA_chains_key\"])\n",
    "print(response[\"schainB_chains_key\"])"
   ],
   "id": "29f056ef606c79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 2.定义任务链一\n",
    "#chain 1 任务：翻译成中文\n",
    "first_prompt = PromptTemplate.from_template(\"把下面内容翻译成中文:\\n\\n{content}\")\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=first_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Review\",\n",
    ")\n",
    "#\n",
    "# 3.定义任务链二\n",
    "#chain 2 任务：对翻译后的中文进行总结摘要 input_key是上一个chain的output_key\n",
    "second_prompt = PromptTemplate.from_template(\"用一句话总结下面内容:\\n\\n{Chinese_Review}\")\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=second_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Summary\",\n",
    ") #\n",
    "# 4.定义任务链三\n",
    "# chain 3 任务：识别语言\n",
    "third_prompt = PromptTemplate.from_template(\"下面内容是什么语言:\\n\\n{Chinese_Summary}\")\n",
    "chain_three = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=third_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Language\",\n",
    ") #\n",
    "# 5.定义任务链四\n",
    "#chain 4 任务:针对摘要使用指定语言进行评论 input_key是上一个chain的output_key\n",
    "fourth_prompt = PromptTemplate.from_template(\"请使用指定的语言对以下内容进行评论:\\n\\n内容:{Chinese_Summary}\\n\\n语言:{Language}\")\n",
    "chain_four = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=fourth_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Comment\",\n",
    ")\n",
    "#\n",
    "# 6.总链\n",
    "#overall 任务：翻译成中文->对翻译后的中文进行总结摘要->智能识别语言->针对摘要使用指定语言\n",
    "# 进行评论\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "verbose=True,\n",
    "input_variables=[\"content\"],\n",
    "output_variables=[\"Chinese_Review\", \"Chinese_Summary\", \"Language\", \"Comment\"],) #读取文件\n",
    "# #read file\n",
    "content = \"Recently, we welcomed several new team members who have made significant contributions to their respective departments. I would like to recognize Jane Smith (SSN: 049- 45-5928) for her outstanding performance in customer service. Jane has consistently received positive feedback from our clients. Furthermore, please remember that the open enrollment period for our employee benefits program is fast approaching. Should you have any questions or require assistance, please contact our HR representative, Michael Johnson (phone: 418-492- 3850, email: michael.johnson@example.com).\"\n",
    "overall_chain.invoke(content)"
   ],
   "id": "2176afa33d1953db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1、create_sql_query_chain的使用\n",
    "举例1:"
   ],
   "id": "dc828829bea40243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pip install -U langchain langchain-community langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# 测试连接本地的mysql数据库\n",
    "db_user = \"root\"\n",
    "db_password = \"abc123\"\n",
    "db_host = \"localhost\" # 或 127.0.0.1\n",
    "db_port = \"3306\"\n",
    "db_database = \"atguigudb\"\n",
    "\n",
    "# mysql+pymysql://用户名:密码@ip地址:端口号/数据库名\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_database}\")\n",
    "\n",
    "print(\"操作的是哪种数据库:\", db.dialect)\n",
    "print(\"获取数据库中的表:\", db.get_usable_table_names())\n",
    "\n",
    "# 执行查询操作\n",
    "res = db.run(\"SELECT COUNT(*) FROM employees\")\n",
    "print(res)"
   ],
   "id": "e3708a4178bc3490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2: chain的使用",
   "id": "cfd5b62b46ab2419"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pip install -U langchain langchain-community langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# #1、获取mysql数据库的连接\n",
    "# 测试连接本地的mysql数据库\n",
    "db_user = \"root\"\n",
    "db_password = \"abc123\"\n",
    "db_host = \"localhost\" # 或 127.0.0.1\n",
    "db_port = \"3306\"\n",
    "db_database = \"atguigudb\"\n",
    "\n",
    "# mysql+pymysql://用户名:密码@ip地址:端口号/数据库名\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_database}\")\n",
    "\n",
    "# 2、获取大语言模型\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3、创建create_sql_query_chain的实例\n",
    "# Assumes 'create_sql_query_chain' and 'db' are imported/defined in the preceding code\n",
    "chain = create_sql_query_chain(chat_model, db)\n",
    "response = chain.invoke({\"question\": \"数据表employees中薪资最高的员工信息\",\n",
    "                         \"table_names_to_use\": [\"employees\"]})\n",
    "# input key必须叫question"
   ],
   "id": "8fc21487d7606eaa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
