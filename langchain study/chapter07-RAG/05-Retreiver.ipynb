{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.导入相关依赖 (Import necessary dependencies)\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 2.定义文档加载器 (Define the document loader)\n",
    "loader = TextLoader(file_path='./asset/load/09-ai1.txt',encoding=\"utf-8\")\n",
    "\n",
    "# 3.加载文档 (Load the document)\n",
    "documents = loader.load()\n",
    "\n",
    "# 4.定义文本切割器 (Define the text splitter)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "# 5.切割文档 (Split the document)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 6.定义嵌入模型 (Define the embedding model)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-large\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 获取向量数据库 (Get the vector database)\n",
    "db = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "\n",
    "# 基于向量数据库获取检索器 (Get the retriever based on the vector database)\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# 进行数据的检索 (Perform data retrieval)\n",
    "docs = retriever.invoke(input = \"深度学习是什么?\")\n",
    "\n",
    "print(len(docs))\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"----{doc}\")"
   ],
   "id": "8d015f544bc9565",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.导入相关依赖 (Import necessary dependencies)\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 2.定义文档 (Define Documents)\n",
    "document_1 = Document(\n",
    "    page_content=\"经济复苏: 美国经济正在从疫情中强劲复苏，失业率降至历史低点。!\",\n",
    ")\n",
    "document_2 = Document(\n",
    "    page_content=\"基础设施: 政府将投资1万亿美元用于修复道路、桥梁和宽带网络。\",\n",
    ")\n",
    "document_3 = Document(\n",
    "    page_content=\"气候变化: 承诺到2030年将温室气体排放量减少50%。\",\n",
    ")\n",
    "document_4 = Document(\n",
    "    page_content=\"医疗保健: 降低处方药的价格，扩大医疗保险覆盖范围。\",\n",
    ")\n",
    "document_5 = Document(\n",
    "    page_content=\"教育: 提供免费的社区大学教育。\",\n",
    ")\n",
    "document_6 = Document(\n",
    "    page_content=\"科技: 增加对半导体产业的投资以减少对外围供应链的依赖。\",\n",
    ")\n",
    "document_7 = Document(\n",
    "    page_content=\"外交政策: 继续支持乌克兰对抗俄罗斯的侵略。\",\n",
    ")\n",
    "document_8 = Document(\n",
    "    page_content=\"枪支管制: 呼吁国会通过更严格的枪支管制法律。\",\n",
    ")\n",
    "document_9 = Document(\n",
    "    page_content=\"移民改革: 提出全面的移民改革方案。\",\n",
    ")\n",
    "document_10 = Document(\n",
    "    page_content=\"社会正义: 承诺解决系统性种族歧视问题。\",\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "\n",
    "# 3.创建向量存储 (Create Vector Store)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# 4.将文档向量化, 添加到向量数据库索引中, 得到向量数据库对象 (Vectorize documents, add to vector DB index, get DB object)\n",
    "db = FAISS.from_documents(documents, embeddings)"
   ],
   "id": "6843ec6fd83c8b9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 默认检索器使用相似性搜索 (Default retriever uses similarity search)",
   "id": "3ed436660f1f77d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 获取检索器 (Get the retriever)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4}) # 这里设置返回的文档数 (Sets the number of documents to return here)\n",
    "\n",
    "docs = retriever.invoke(\"经济政策\")\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n结果 {i+1}:\\n{doc.page_content}\\n\")"
   ],
   "id": "fa20d9003a9b0311",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "3、结合大模型的使用 (3. Combining the Use of Large Models)\n",
    "\n",
    "示例1: 不使用RAG技术 (Example 1: Without using RAG technology)\n",
    "[A single-line input field, likely for code or text]\n",
    "\n",
    "示例2: 通过FAISS构建一个可搜索的向量索引数据库, 并结合RAG技术让LLM去回答问题。\n",
    "(Example 2: Use FAISS to build a searchable vector index database, and combine it with RAG technology to let the LLM answer questions.)"
   ],
   "id": "d60fddbdfa425e53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 设置环境变量 (Set environment variables)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY1')\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('OPENAI_BASE_URL')\n",
    "\n",
    "# 创建大模型实例 (Create large model instance)\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 调用 (Invoke)\n",
    "response = llm.invoke(\"北京有什么著名的建筑？\")\n",
    "print(response.content)"
   ],
   "id": "602f56cf8fe9110e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "情况2：使用RAG给LLM灌输上下文数据\n",
   "id": "14fb3b4fb573ced6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.导入所有需要的包 (Import all required packages)\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# 2.创建自定义提示词模板 (Create custom prompt template)\n",
    "prompt_template = \"\"\"请使用以下提供的文本内容来回答问题，仅使用提供的文本信息。如果文本中没有相关信息，请回答\"抱歉，提供的文本中没有这个信息\"。\n",
    "\n",
    "文本内容:\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\n",
    "回答:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 3.初始化模型 (Initialize model)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "# 4.加载文档 (Load documents)\n",
    "loader = TextLoader(\n",
    "    \"./asset/load/10-test_doc.txt\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "# 5.分割文档 (Split documents)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "#print(f\"文档个数:{len(texts)}\") # Print the number of documents (chunks)\n",
    "\n",
    "# 6.创建向量存储 (Create vector store)\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# 7.获取检索器 (Get retriever)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 8.检索 (Retrieve)\n",
    "docs = retriever.invoke(\"北京有什么著名的建筑？\")\n",
    "\n",
    "# 9.创建Runnable链 (Create Runnable chain)\n",
    "chain = prompt | llm\n",
    "\n",
    "# 10.提问 (Ask question)\n",
    "result = chain.invoke(\n",
    "    input={\"question\": \"北京有什么著名的建筑？\", \"context\": docs}\n",
    ")\n",
    "print(f\"\\n回答:\\n\", result.content)"
   ],
   "id": "4fee40d4cb64d31b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
